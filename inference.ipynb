{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep-coder inference",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yje9hqtcUQ_f",
        "colab_type": "text"
      },
      "source": [
        "### Initialization\n",
        "* Check whether the runtime is host or local.\n",
        "* Mount Google Drive when using the host runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwqGy_GyUQnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "  runtime = \"host\"\n",
        "except:\n",
        "  runtime = \"local\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S457sT6QMUr",
        "colab_type": "text"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QN-4eF51DNqt",
        "colab": {}
      },
      "source": [
        "#@title Parameters\n",
        "#@markdown |Name            |Description|\n",
        "#@markdown |:---            |:---|\n",
        "#@markdown |`seed`|The random seed|\n",
        "seed = 3984 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### `deep-coder` Repositories\n",
        "#@markdown |Name            |Description|\n",
        "#@markdown |:---            |:---|\n",
        "#@markdown |`repository_url`|The URL of `deep-coder` git repository (enabled only in the host runtime)|\n",
        "#@markdown |`branch_name`   |The branch name (enabled only in the host runtime)|\n",
        "repository_url = \"https://github.com/HiroakiMikami/deep-coder\" #@param {type: \"string\"}\n",
        "branch_name = \"master\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown ### Settings\n",
        "#@markdown |Name    |Description|\n",
        "#@markdown |:---    |:---|\n",
        "#@markdown |`device`|The id of GPU. `-1` means that CPU is used.|\n",
        "device = 0 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### URLs\n",
        "#@markdown |Name              |Description|\n",
        "#@markdown |:---              |:---|\n",
        "#@markdown |`model_shape_path`|The file path of the model shape.|\n",
        "#@markdown |`model_path`      |The file of the model parameters.|\n",
        "model_shape_path = \"./examples/medium/trained-model/model-shape.pickle\" #@param {type: \"string\"}\n",
        "model_path = \"./examples/medium/trained-model/model.npz\" #@param {type: \"string\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BembldCdOO1",
        "colab_type": "text"
      },
      "source": [
        "### Setup\n",
        "* Fix the random seed\n",
        "* Download the codebase\n",
        "  1. Clone git repository and move to the specified branch\n",
        "  2. Initialize submodule\n",
        "  3. Install chainer and cupy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwjlAkY1fR5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "SEED_MAX = 2**32 - 1\n",
        "\n",
        "root_rng = np.random.RandomState(seed)\n",
        "random.seed(root_rng.randint(SEED_MAX))\n",
        "np.random.seed(root_rng.randint(SEED_MAX))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIZJmuz8QFn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if runtime == \"host\":\n",
        "  %cd /content\n",
        "  !rm -rf deep-coder\n",
        "  ![ ! -e deep-coder ] && git clone $repository_url deep-coder\n",
        "  %cd deep-coder\n",
        "  !git checkout origin/$branch_name\n",
        "  !git submodule init\n",
        "  !git submodule update\n",
        "  !make -C DeepCoder_Utils/enumerative-search -j `nproc`\n",
        "  !curl https://colab.chainer.org/install | sh -\n",
        "  !pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz7sdzxUi70b",
        "colab_type": "text"
      },
      "source": [
        "### Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7kdglcUjDTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = [[1, [-1, 3, 2, 4, -5]], [0, [-2, 2, 3, 3]], [2, [1, 2, 3]], [1, [0, 1, 2]]] #@param {type: \"raw\"}\n",
        "outputs = [-1, -2, 3, 1] #@param {type: \"raw\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4IOCX_PXG6sH"
      },
      "source": [
        "### Run Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SsVdGBe4G6sJ",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "import chainer as ch\n",
        "from chainer import datasets\n",
        "from src.dataset import EncodedDataset, Dataset\n",
        "import src.inference as I\n",
        "from src.model import ModelShapeParameters\n",
        "from src.dataset import Example\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "with open(model_shape_path, \"rb\") as f:\n",
        "  model_shape = pickle.load(f)\n",
        "\n",
        "  model = I.InferenceModel(model_shape)\n",
        "ch.serializers.load_npz(model_path, model.predictor)\n",
        "\n",
        "pred = I.predict_with_neural_network(model_shape, model)\n",
        "\n",
        "\n",
        "examples = [Example(inputs, output) for inputs, output in zip(inputs, outputs)]\n",
        "print(examples)\n",
        "result = I.search(\n",
        "    os.path.join(os.getcwd(), \"DeepCoder_Utils\",\n",
        "                 \"enumerative-search\", \"search\"),\n",
        "    100,\n",
        "    model_shape.dataset_metadata.value_range,\n",
        "    examples,\n",
        "    2,\n",
        "    pred)\n",
        "\n",
        "if result.is_solved:\n",
        "    print(\"Time: {} sec\".format(result.time_seconds))\n",
        "    print(\"#ExploredNodes: {}\".format(result.explored_nodes))\n",
        "    print(result.solution)\n",
        "else:\n",
        "    print(\"Failed to synthesize\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train (length=1)",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yje9hqtcUQ_f",
        "colab_type": "text"
      },
      "source": [
        "### Initialization\n",
        "* Check whether the runtime is host or local.\n",
        "* Mount Google Drive when using the host runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwqGy_GyUQnw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "766eb6c9-f528-4847-9375-06dc540fdefe"
      },
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "  runtime = \"host\"\n",
        "except:\n",
        "  runtime = \"local\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S457sT6QMUr",
        "colab_type": "text"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QN-4eF51DNqt",
        "colab": {}
      },
      "source": [
        "#@title Parameters\n",
        "#@markdown |Name            |Description|\n",
        "#@markdown |:---            |:---|\n",
        "#@markdown |`seed`|The random seed|\n",
        "seed = 3984 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### `deep-coder` Repositories\n",
        "#@markdown |Name            |Description|\n",
        "#@markdown |:---            |:---|\n",
        "#@markdown |`repository_url`|The URL of `deep-coder` git repository (enabled only in the host runtime)|\n",
        "#@markdown |`branch_name`   |The branch name (enabled only in the host runtime)|\n",
        "repository_url = \"https://github.com/HiroakiMikami/deep-coder\" #@param {type: \"string\"}\n",
        "branch_name = \"master\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown ### Model Parameters\n",
        "#@markdown |Name               |Description|\n",
        "#@markdown |:---               |:---|\n",
        "#@markdown |`n_embed`          |The dimension of integer embeddings|\n",
        "#@markdown |`n_units`          |The number of units in the hidden layers|\n",
        "#@markdown |`num_hidden_layers`|The number of the hidden layers|\n",
        "n_embed = 2 #@param {type: \"number\"}\n",
        "n_units = 256 #@param {type: \"number\"}\n",
        "num_hidden_layers = 3 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Training Settings\n",
        "#@markdown |Name                |Description|\n",
        "#@markdown |:---                |:---|\n",
        "#@markdown |`batch_size`        |The minibatch size|\n",
        "#@markdown |`weight_label_false`|The weight for the loss value in the case of attribute=False. `-1` means that using the original loss function|\n",
        "#@markdown |`num_epochs`        |The numer of epoch|\n",
        "#@markdown |`ratio_test`        |The ratio of entries for testing|\n",
        "#@markdown |`num_train`         |The number of entries used for training|\n",
        "batch_size = 1 #@param {type: \"number\"}\n",
        "weight_label_false = -1 #@param {type: \"number\"}\n",
        "num_epochs = 100 #@param {type: \"number\"}\n",
        "ratio_test = 0 #@param {type: \"number\"}\n",
        "num_train = 0 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Validation Settings\n",
        "#@markdown |Name                |Description|\n",
        "#@markdown |:---                |:---|\n",
        "#@markdown |`timeout_second`    ||\n",
        "#@markdown |`max_program_length`|The maximum length of the program|\n",
        "timeout_second = 1 #@param {type: \"number\"}\n",
        "max_program_length = 1 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Other Settings\n",
        "#@markdown |Name    |Description|\n",
        "#@markdown |:---    |:---|\n",
        "#@markdown |`device`|The id of GPU. `-1` means that CPU is used.|\n",
        "device = 0 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Filepath\n",
        "#@markdown |Name                |Description|\n",
        "#@markdown |:---                |:---|\n",
        "#@markdown |`train_dataset_path`|The file path of the training dataset.|\n",
        "#@markdown |`valid_dataset_path`|The file path of the validation dataset.|\n",
        "#@markdown |`destination_path`  |The directory of the directory that will contain the training results.|\n",
        "train_dataset_path = \"/gdrive/My Drive/DeepCoder/dataset/length_1/train.pickle\" #@param {type: \"string\"}\n",
        "valid_dataset_path = \"/gdrive/My Drive/DeepCoder/dataset/length_1/valid.pickle\" #@param {type: \"string\"}\n",
        "destination_path = \"/gdrive/My Drive/DeepCoder/out/length_1/\" #@param {type: \"string\"}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BembldCdOO1",
        "colab_type": "text"
      },
      "source": [
        "### Setup\n",
        "* Fix the random seed\n",
        "* Download the codebase\n",
        "  1. Clone git repository and move to the specified branch\n",
        "  2. Initialize submodule\n",
        "  3. Install chainer and cupy\n",
        "* Copy the dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwjlAkY1fR5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "SEED_MAX = 2**32 - 1\n",
        "\n",
        "root_rng = np.random.RandomState(seed)\n",
        "random.seed(root_rng.randint(SEED_MAX))\n",
        "np.random.seed(root_rng.randint(SEED_MAX))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIZJmuz8QFn_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "0a8d3d25-e8bd-4115-8ff2-c80548c82094"
      },
      "source": [
        "if runtime == \"host\":\n",
        "  %cd /content\n",
        "  !rm -rf deep-coder\n",
        "  ![ ! -e deep-coder ] && git clone $repository_url deep-coder\n",
        "  %cd deep-coder\n",
        "  !git checkout origin/$branch_name\n",
        "  !git submodule init\n",
        "  !git submodule update\n",
        "  !make -C DeepCoder_Utils/enumerative-search -j `nproc`\n",
        "  !curl https://colab.chainer.org/install | sh -\n",
        "  !pip install tqdm"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'deep-coder'...\n",
            "remote: Enumerating objects: 114, done.\u001b[K\n",
            "remote: Counting objects: 100% (114/114), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 1238 (delta 70), reused 64 (delta 34), pack-reused 1124\u001b[K\n",
            "Receiving objects: 100% (1238/1238), 17.80 MiB | 2.23 MiB/s, done.\n",
            "Resolving deltas: 100% (748/748), done.\n",
            "/content/deep-coder\n",
            "Note: checking out 'origin/master'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at cbf6f06 Add example script to generate the dataset\n",
            "Submodule 'DeepCoder_Utils' (https://github.com/HiroakiMikami/DeepCoder-Utils.git) registered for path 'DeepCoder_Utils'\n",
            "Cloning into '/content/deep-coder/DeepCoder_Utils'...\n",
            "Submodule path 'DeepCoder_Utils': checked out '10330caf96b2f6bf354c512010b356a7b0d1dba5'\n",
            "make: Entering directory '/content/deep-coder/DeepCoder_Utils/enumerative-search'\n",
            "g++ -std=c++11 -O3   successor.cc -c -o successor.o\n",
            "g++ -std=c++11 -O3   ops.cc -c -o ops.o\n",
            "g++ -std=c++11 -O3   program_state.cc -c -o program_state.o\n",
            "g++ -std=c++11 -O3   main.cc -c -o main.o\n",
            "g++ -std=c++11 -O3   datum.cc -c -o datum.o\n",
            "g++ -std=c++11 -O3   depth_first_search.cc -c -o depth_first_search.o\n",
            "g++ -std=c++11 -O3   utils.cc -c -o utils.o\n",
            "g++ -std=c++11 -O3   io_set.cc -c -o io_set.o\n",
            "g++ -std=c++11 -O3  successor.o ops.o program_state.o main.o datum.o depth_first_search.o utils.o io_set.o -o search\n",
            "make: Leaving directory '/content/deep-coder/DeepCoder_Utils/enumerative-search'\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1580  100  1580    0     0   4730      0 --:--:-- --:--:-- --:--:--  4730\n",
            "+ apt -y -q install cuda-libraries-dev-10-0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n",
            "+ pip install -q cupy-cuda100  chainer \n",
            "+ set +ex\n",
            "Installation succeeded!\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz7sdzxUi70b",
        "colab_type": "text"
      },
      "source": [
        "### Train DNN Model\n",
        "* Create `Trainer`\n",
        "* Run training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7kdglcUjDTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "import chainer as ch\n",
        "from chainer import datasets\n",
        "from chainer.training import extensions\n",
        "from src.dataset import EncodedDataset, Dataset\n",
        "import src.train as T\n",
        "from src.model import ModelShapeParameters\n",
        "\n",
        "with open(train_dataset_path, \"rb\") as f:\n",
        "    d: Dataset = pickle.load(f)\n",
        "dataset = d.dataset\n",
        "metadata = d.metadata\n",
        "    \n",
        "\n",
        "if num_train != 0:\n",
        "    num_test = int(num_train *\n",
        "                   (ratio_test if ratio_test is not None else 0.0))\n",
        "    dataset, _ = datasets.split_dataset_random(\n",
        "        dataset, num_train + num_test, seed=root_rng.randint(SEED_MAX))\n",
        "\n",
        "model_shape = ModelShapeParameters(metadata, num_hidden_layers, n_embed, n_units)\n",
        "\n",
        "n_entries = len(dataset)\n",
        "dataset = EncodedDataset(Dataset(dataset, metadata))\n",
        "if ratio_test is None or ratio_test == 0:\n",
        "    train = dataset\n",
        "    test = None\n",
        "else:\n",
        "    train, test = datasets.split_dataset_random(dataset, int(\n",
        "        n_entries * (1.0 - ratio_test)), seed=root_rng.randint(SEED_MAX))\n",
        "\n",
        "train_iter = ch.iterators.SerialIterator(train, batch_size)\n",
        "if test is not None:\n",
        "    test_iter = ch.iterators.SerialIterator(\n",
        "        test, batch_size, repeat=False, shuffle=False)\n",
        "else:\n",
        "    test_iter = None\n",
        "\n",
        "train = T.Training(train_iter, test_iter, destination_path, model_shape, weight_label_false,\n",
        "                   num_epochs, device=device)\n",
        "train.trainer.extend(extensions.LogReport())\n",
        "if test_iter is not None:\n",
        "    train.trainer.extend(extensions.PrintReport(\n",
        "        ['epoch',\n",
        "         'main/loss', 'validation/main/loss',\n",
        "         'main/accuracy', 'main/accuracy_false', 'main/accuracy_true',\n",
        "         'validation/main/accuracy', 'validation/main/accuracy_false', 'validation/main/accuracy_true',\n",
        "         'elapsed_time']))\n",
        "else:\n",
        "    train.trainer.extend(extensions.PrintReport(\n",
        "        ['epoch', 'main/loss', 'main/accuracy', 'main/accuracy_false', 'main/accuracy_true', 'elapsed_time']))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl4xN2N2kGfo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b66c4bc-fff2-4ae7-93b9-191e6548c8ec"
      },
      "source": [
        "train.trainer.run()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch       main/loss   main/accuracy  main/accuracy_false  main/accuracy_true  elapsed_time\n",
            "\u001b[J1           0.299507    0.90571        0.954044             0.0294118           9.53025       \n",
            "\u001b[J2           0.190456    0.948097       1                    0                   9.7745        \n",
            "\u001b[J3           0.189035    0.948097       1                    0                   10.0176       \n",
            "\u001b[J4           0.18964     0.948097       1                    0                   10.257        \n",
            "\u001b[J5           0.187792    0.948097       1                    0                   10.503        \n",
            "\u001b[J6           0.187395    0.948097       1                    0                   10.7499       \n",
            "\u001b[J7           0.182942    0.948097       1                    0                   10.9909       \n",
            "\u001b[J8           0.17956     0.948097       1                    0                   11.2342       \n",
            "\u001b[J9           0.176796    0.949827       0.996324             0.0882353           11.5084       \n",
            "\u001b[J10          0.170745    0.951557       0.999081             0.0735294           11.7524       \n",
            "\u001b[J11          0.16569     0.952422       1                    0.0735294           11.9932       \n",
            "\u001b[J12          0.156281    0.955018       0.999081             0.132353            12.2353       \n",
            "\u001b[J13          0.151187    0.955883       1                    0.132353            12.4828       \n",
            "\u001b[J14          0.147858    0.955883       1                    0.132353            12.7258       \n",
            "\u001b[J15          0.142377    0.955883       1                    0.132353            12.9729       \n",
            "\u001b[J16          0.137403    0.956748       0.999109             0.161765            13.2192       \n",
            "\u001b[J17          0.13497     0.955883       0.999109             0.147059            13.4679       \n",
            "\u001b[J18          0.128158    0.959343       0.999081             0.205882            13.713        \n",
            "\u001b[J19          0.124812    0.960208       1                    0.205882            13.9837       \n",
            "\u001b[J20          0.122205    0.961073       1                    0.220588            14.2302       \n",
            "\u001b[J21          0.120341    0.960208       0.999081             0.220588            14.4823       \n",
            "\u001b[J22          0.116918    0.961073       1                    0.220588            14.731        \n",
            "\u001b[J23          0.113257    0.961938       1                    0.235294            14.9743       \n",
            "\u001b[J24          0.110839    0.962803       1                    0.25                15.2311       \n",
            "\u001b[J25          0.108022    0.963668       1                    0.264706            15.476        \n",
            "\u001b[J26          0.105556    0.964533       1                    0.279412            15.7323       \n",
            "\u001b[J27          0.101799    0.964533       1                    0.279412            15.9777       \n",
            "\u001b[J28          0.10122     0.964533       1                    0.279412            16.2442       \n",
            "\u001b[J29          0.0977978   0.967128       0.999109             0.338235            16.485        \n",
            "\u001b[J30          0.0948175   0.966263       1                    0.308824            16.7311       \n",
            "\u001b[J31          0.0918727   0.970589       1                    0.382353            16.9762       \n",
            "\u001b[J32          0.0900474   0.970588       1                    0.382353            17.2166       \n",
            "\u001b[J33          0.0876474   0.971454       0.999081             0.411765            17.4767       \n",
            "\u001b[J34          0.0853547   0.971454       1                    0.397059            17.7395       \n",
            "\u001b[J35          0.0833946   0.974049       1                    0.441176            17.9829       \n",
            "\u001b[J36          0.0815545   0.970588       0.999081             0.397059            18.2328       \n",
            "\u001b[J37          0.0803405   0.973184       1                    0.426471            18.5156       \n",
            "\u001b[J38          0.0778751   0.973184       1                    0.426471            18.7723       \n",
            "\u001b[J39          0.0744736   0.973184       1                    0.426471            19.0231       \n",
            "\u001b[J40          0.0738477   0.974049       1                    0.441176            19.2736       \n",
            "\u001b[J41          0.0720532   0.972319       0.998162             0.441176            19.5204       \n",
            "\u001b[J42          0.0685444   0.975779       1                    0.485294            19.7753       \n",
            "\u001b[J43          0.0661524   0.977509       1                    0.514706            20.0296       \n",
            "\u001b[J44          0.0639211   0.978374       1                    0.544118            20.2904       \n",
            "\u001b[J45          0.0635528   0.977509       1                    0.514706            20.5455       \n",
            "\u001b[J46          0.0614124   0.979239       1                    0.544118            20.8195       \n",
            "\u001b[J47          0.0595723   0.978374       1                    0.529412            21.074        \n",
            "\u001b[J48          0.057682    0.980969       1                    0.588235            21.319        \n",
            "\u001b[J49          0.0571351   0.980969       1                    0.588235            21.573        \n",
            "\u001b[J50          0.0552279   0.981834       1                    0.602941            21.8302       \n",
            "\u001b[J51          0.0535526   0.980969       1                    0.588235            22.0798       \n",
            "\u001b[J52          0.0522495   0.981834       1                    0.602941            22.328        \n",
            "\u001b[J53          0.0511297   0.981834       1                    0.602941            22.6056       \n",
            "\u001b[J54          0.0499142   0.982699       1                    0.632353            22.8647       \n",
            "\u001b[J55          0.0475092   0.983564       1                    0.661765            23.1178       \n",
            "\u001b[J56          0.0461011   0.983564       1                    0.661765            23.3779       \n",
            "\u001b[J57          0.0451477   0.983564       1                    0.661765            23.6365       \n",
            "\u001b[J58          0.044456    0.983564       1                    0.661765            23.8922       \n",
            "\u001b[J59          0.042825    0.985294       1                    0.691176            24.2219       \n",
            "\u001b[J60          0.0424853   0.985294       1                    0.691176            24.5097       \n",
            "\u001b[J61          0.0405768   0.986159       1                    0.705882            24.771        \n",
            "\u001b[J62          0.0401339   0.984429       1                    0.676471            25.0237       \n",
            "\u001b[J63          0.0376793   0.983564       1                    0.661765            25.2854       \n",
            "\u001b[J64          0.0362267   0.986159       1                    0.705882            25.5452       \n",
            "\u001b[J65          0.0350662   0.988755       1                    0.75                25.8082       \n",
            "\u001b[J66          0.0340381   0.987889       1                    0.735294            26.0734       \n",
            "\u001b[J67          0.0329616   0.988755       0.999109             0.764706            26.3673       \n",
            "\u001b[J68          0.0316525   0.988755       1                    0.75                26.6205       \n",
            "\u001b[J69          0.0303612   0.98962        1                    0.764706            26.8909       \n",
            "\u001b[J70          0.0294823   0.990484       0.999109             0.794118            27.1464       \n",
            "\u001b[J71          0.0283008   0.99135        1                    0.808824            27.4035       \n",
            "\u001b[J72          0.0265311   0.992215       1                    0.808824            27.6627       \n",
            "\u001b[J73          0.0258797   0.992215       1                    0.808824            27.9549       \n",
            "\u001b[J74          0.0251484   0.992215       0.999109             0.823529            28.2341       \n",
            "\u001b[J75          0.0239135   0.99308        1                    0.838235            28.487        \n",
            "\u001b[J76          0.0229923   0.99481        1                    0.867647            28.7471       \n",
            "\u001b[J77          0.0225992   0.993945       1                    0.852941            29.0095       \n",
            "\u001b[J78          0.0217102   0.99481        1                    0.867647            29.2814       \n",
            "\u001b[J79          0.0208158   0.995675       0.999109             0.897059            29.5363       \n",
            "\u001b[J80          0.0204024   0.99481        1                    0.867647            29.7994       \n",
            "\u001b[J81          0.0205939   0.995675       1                    0.882353            30.0798       \n",
            "\u001b[J82          0.0208219   0.99308        0.999109             0.852941            30.3438       \n",
            "\u001b[J83          0.0198475   0.99654        0.999109             0.926471            30.6017       \n",
            "\u001b[J84          0.0176973   0.99654        1                    0.897059            30.8663       \n",
            "\u001b[J85          0.0166162   0.997405       1                    0.926471            31.1206       \n",
            "\u001b[J86          0.016562    0.997405       1                    0.926471            31.3916       \n",
            "\u001b[J87          0.0157279   0.997405       1                    0.926471            31.6872       \n",
            "\u001b[J88          0.0160411   0.99827        1                    0.955882            31.9582       \n",
            "\u001b[J89          0.0143385   0.997405       1                    0.926471            32.2172       \n",
            "\u001b[J90          0.0140857   0.99827        1                    0.955882            32.4776       \n",
            "\u001b[J91          0.0135489   0.99827        1                    0.955882            32.7313       \n",
            "\u001b[J92          0.0127609   0.99827        0.999109             0.970588            33.0016       \n",
            "\u001b[J93          0.0121122   0.999135       1                    0.970588            33.2712       \n",
            "\u001b[J94          0.0118286   0.99827        1                    0.955882            33.569        \n",
            "\u001b[J95          0.0113975   0.999135       1                    0.970588            33.8282       \n",
            "\u001b[J96          0.0109982   0.999135       1                    0.970588            34.1035       \n",
            "\u001b[J97          0.0104666   1              1                    1                   34.3679       \n",
            "\u001b[J98          0.0100692   0.999135       1                    0.970588            34.6361       \n",
            "\u001b[J99          0.00966212  0.999135       1                    0.970588            34.9007       \n",
            "\u001b[J100         0.00943847  0.999135       1                    0.970588            35.203        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sl37YHR_b6L",
        "colab_type": "text"
      },
      "source": [
        "### Save DNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-WYlqxVkO5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import chainer as ch\n",
        "\n",
        "if not os.path.exists(destination_path):\n",
        "    os.makedirs(destination_path)\n",
        "\n",
        "with open(os.path.join(destination_path, \"model-shape.pickle\"), \"wb\") as f:\n",
        "    pickle.dump(model_shape, f)\n",
        "\n",
        "ch.serializers.save_npz(os.path.join(destination_path, \"model.npz\"), train.predictor)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4IOCX_PXG6sH"
      },
      "source": [
        "### Validate DNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SsVdGBe4G6sJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9b3d62a5-fcdf-4ace-82a6-43f7f3b88f29"
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "import chainer as ch\n",
        "from chainer import datasets\n",
        "from src.dataset import EncodedDataset, Dataset\n",
        "import src.inference as I\n",
        "from src.model import ModelShapeParameters\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "model = I.InferenceModel(model_shape)\n",
        "ch.serializers.load_npz(os.path.join(destination_path, \"model.npz\"), model.predictor)\n",
        "\n",
        "with open(valid_dataset_path, \"rb\") as f:\n",
        "    dataset: Dataset = pickle.load(f)\n",
        "\n",
        "pred = I.predict_with_neural_network(model_shape, model)\n",
        "\n",
        "results = dict([])\n",
        "num_succ = 0\n",
        "for i, (entry,) in enumerate(tqdm(dataset.dataset)):\n",
        "    result = I.search(\n",
        "        os.path.join(os.getcwd(), \"DeepCoder_Utils\",\n",
        "                     \"enumerative-search\", \"search\"),\n",
        "        timeout_second,\n",
        "        model_shape.dataset_metadata.value_range,\n",
        "        entry.examples,\n",
        "        max_program_length,\n",
        "        pred\n",
        "    )\n",
        "    results[i] = result\n",
        "    if result.is_solved:\n",
        "        num_succ += 1\n",
        "\n",
        "print(\"Solved: {} of {} examples\".format(num_succ, len(dataset.dataset)))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8783f64acad40df84b1f5375eb86c43",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Solved: 5 of 5 examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lhq-S-vcGxUQ"
      },
      "source": [
        "### Save Validation Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DuxS691_fuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(destination_path):\n",
        "    os.makedirs(destination_path)\n",
        "\n",
        "with open(os.path.join(destination_path, \"result.pickle\"), \"wb\") as f:\n",
        "    pickle.dump(results, f)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
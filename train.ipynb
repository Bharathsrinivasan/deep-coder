{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep-coder train",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yje9hqtcUQ_f",
        "colab_type": "text"
      },
      "source": [
        "### Initialization\n",
        "* Check whether the runtime is host or local.\n",
        "* Mount Google Drive when using the host runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwqGy_GyUQnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "  runtime = \"host\"\n",
        "except:\n",
        "  runtime = \"local\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S457sT6QMUr",
        "colab_type": "text"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QN-4eF51DNqt",
        "colab": {}
      },
      "source": [
        "#@title Parameters\n",
        "#@markdown |Name            |Description|\n",
        "#@markdown |:---            |:---|\n",
        "#@markdown |`seed`|The random seed|\n",
        "seed = 3984 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### `deep-coder` Repositories\n",
        "#@markdown |Name            |Description|\n",
        "#@markdown |:---            |:---|\n",
        "#@markdown |`repository_url`|The URL of `deep-coder` git repository (enabled only in the host runtime)|\n",
        "#@markdown |`branch_name`   |The branch name (enabled only in the host runtime)|\n",
        "repository_url = \"https://github.com/HiroakiMikami/deep-coder\" #@param {type: \"string\"}\n",
        "branch_name = \"master\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown ### Model Parameters\n",
        "#@markdown |Name               |Description|\n",
        "#@markdown |:---               |:---|\n",
        "#@markdown |`n_embed`          |The dimension of integer embeddings|\n",
        "#@markdown |`n_units`          |The number of units in the hidden layers|\n",
        "#@markdown |`num_hidden_layers`|The number of the hidden layers|\n",
        "n_embed = 20 #@param {type: \"number\"}\n",
        "n_units = 256 #@param {type: \"number\"}\n",
        "num_hidden_layers = 3 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Training Settings\n",
        "#@markdown |Name                |Description|\n",
        "#@markdown |:---                |:---|\n",
        "#@markdown |`batch_size`        |The minibatch size|\n",
        "#@markdown |`weight_label_false`|The weight for the loss value in the case of attribute=False. `-1` means that using the original loss function|\n",
        "#@markdown |`num_epochs`        |The numer of epoch|\n",
        "#@markdown |`ratio_test`        |The ratio of entries for testing|\n",
        "#@markdown |`num_train`         |The number of entries used for training|\n",
        "batch_size = 32 #@param {type: \"number\"}\n",
        "weight_label_false = -1 #@param {type: \"number\"}\n",
        "num_epochs = 10 #@param {type: \"number\"}\n",
        "ratio_test = 0 #@param {type: \"number\"}\n",
        "num_train = 0 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Validation Settings\n",
        "#@markdown |Name                |Description|\n",
        "#@markdown |:---                |:---|\n",
        "#@markdown |`timeout_second`    ||\n",
        "#@markdown |`max_program_length`|The maximum length of the program|\n",
        "timeout_second = 1 #@param {type: \"number\"}\n",
        "max_program_length = 2 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Other Settings\n",
        "#@markdown |Name    |Description|\n",
        "#@markdown |:---    |:---|\n",
        "#@markdown |`device`|The id of GPU. `-1` means that CPU is used.|\n",
        "device = 0 #@param {type: \"number\"}\n",
        "\n",
        "#@markdown ### Filepath\n",
        "#@markdown |Name                |Description|\n",
        "#@markdown |:---                |:---|\n",
        "#@markdown |`train_dataset_path`|The file path of the training dataset.|\n",
        "#@markdown |`valid_dataset_path`|The file path of the validation dataset.|\n",
        "#@markdown |`destination_path`  |The directory of the directory that will contain the training results.|\n",
        "train_dataset_path = \"./dataset/train.pickle\" #@param {type: \"string\"}\n",
        "valid_dataset_path = \"./dataset/valid.pickle\" #@param {type: \"string\"}\n",
        "destination_path = \"./out\" #@param {type: \"string\"}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BembldCdOO1",
        "colab_type": "text"
      },
      "source": [
        "### Setup\n",
        "* Fix the random seed\n",
        "* Download the codebase\n",
        "  1. Clone git repository and move to the specified branch\n",
        "  2. Initialize submodule\n",
        "  3. Install chainer and cupy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwjlAkY1fR5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "SEED_MAX = 2**32 - 1\n",
        "\n",
        "root_rng = np.random.RandomState(seed)\n",
        "random.seed(root_rng.randint(SEED_MAX))\n",
        "np.random.seed(root_rng.randint(SEED_MAX))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIZJmuz8QFn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if runtime == \"host\":\n",
        "  %cd /content\n",
        "  !rm -rf deep-coder\n",
        "  ![ ! -e deep-coder ] && git clone $repository_url deep-coder\n",
        "  %cd deep-coder\n",
        "  !git checkout origin/$branch_name\n",
        "  !git submodule init\n",
        "  !git submodule update\n",
        "  !make -C DeepCoder_Utils/enumerative-search -j `nproc`\n",
        "  !curl https://colab.chainer.org/install | sh -\n",
        "  !pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz7sdzxUi70b",
        "colab_type": "text"
      },
      "source": [
        "### Train DNN Model\n",
        "* Create `Trainer`\n",
        "* Run training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7kdglcUjDTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "import chainer as ch\n",
        "from chainer import datasets\n",
        "from chainer.training import extensions\n",
        "from src.dataset import EncodedDataset, Dataset\n",
        "import src.train as T\n",
        "from src.model import ModelShapeParameters\n",
        "\n",
        "with open(train_dataset_path, \"rb\") as f:\n",
        "    d: Dataset = pickle.load(f)\n",
        "dataset = d.dataset\n",
        "metadata = d.metadata\n",
        "    \n",
        "\n",
        "if num_train != 0:\n",
        "    num_test = int(num_train *\n",
        "                   (ratio_test if ratio_test is not None else 0.0))\n",
        "    dataset, _ = datasets.split_dataset_random(\n",
        "        dataset, num_train + num_test, seed=root_rng.randint(SEED_MAX))\n",
        "\n",
        "model_shape = ModelShapeParameters(metadata, num_hidden_layers, n_embed, n_units)\n",
        "\n",
        "n_entries = len(dataset)\n",
        "dataset = EncodedDataset(Dataset(dataset, metadata))\n",
        "if ratio_test is None or ratio_test == 0:\n",
        "    train = dataset\n",
        "    test = None\n",
        "else:\n",
        "    train, test = datasets.split_dataset_random(dataset, int(\n",
        "        n_entries * (1.0 - ratio_test)), seed=root_rng.randint(SEED_MAX))\n",
        "\n",
        "train_iter = ch.iterators.SerialIterator(train, batch_size)\n",
        "if test is not None:\n",
        "    test_iter = ch.iterators.SerialIterator(\n",
        "        test, batch_size, repeat=False, shuffle=False)\n",
        "else:\n",
        "    test_iter = None\n",
        "\n",
        "train = T.Training(train_iter, test_iter, destination_path, model_shape, weight_label_false,\n",
        "                   num_epochs, device=device)\n",
        "train.trainer.extend(extensions.LogReport())\n",
        "if test_iter is not None:\n",
        "    train.trainer.extend(extensions.PrintReport(\n",
        "        ['epoch',\n",
        "         'main/loss', 'validation/main/loss',\n",
        "         'main/accuracy', 'main/accuracy_false', 'main/accuracy_true',\n",
        "         'validation/main/accuracy', 'validation/main/accuracy_false', 'validation/main/accuracy_true',\n",
        "         'elapsed_time']))\n",
        "else:\n",
        "    train.trainer.extend(extensions.PrintReport(\n",
        "        ['epoch', 'main/loss', 'main/accuracy', 'main/accuracy_false', 'main/accuracy_true', 'elapsed_time']))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl4xN2N2kGfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.trainer.run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sl37YHR_b6L",
        "colab_type": "text"
      },
      "source": [
        "### Save DNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-WYlqxVkO5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import chainer as ch\n",
        "\n",
        "if not os.path.exists(destination_path):\n",
        "    os.makedirs(destination_path)\n",
        "\n",
        "with open(os.path.join(destination_path, \"model-shape.pickle\"), \"wb\") as f:\n",
        "    pickle.dump(model_shape, f)\n",
        "\n",
        "ch.serializers.save_npz(os.path.join(destination_path, \"model.npz\"), train.predictor)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4IOCX_PXG6sH"
      },
      "source": [
        "### Validate DNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SsVdGBe4G6sJ",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "import chainer as ch\n",
        "from chainer import datasets\n",
        "from src.dataset import EncodedDataset, Dataset\n",
        "import src.inference as I\n",
        "from src.model import ModelShapeParameters\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "model = I.InferenceModel(model_shape)\n",
        "ch.serializers.load_npz(os.path.join(destination_path, \"model.npz\"), model.predictor)\n",
        "\n",
        "with open(valid_dataset_path, \"rb\") as f:\n",
        "    dataset: Dataset = pickle.load(f)\n",
        "\n",
        "pred = I.predict_with_neural_network(model_shape, model)\n",
        "\n",
        "results = dict([])\n",
        "num_succ = 0\n",
        "for i, (entry,) in enumerate(tqdm(dataset.dataset)):\n",
        "    result = I.search(\n",
        "        os.path.join(os.getcwd(), \"DeepCoder_Utils\",\n",
        "                     \"enumerative-search\", \"search\"),\n",
        "        timeout_second,\n",
        "        model_shape.dataset_metadata.value_range,\n",
        "        entry.examples,\n",
        "        max_program_length,\n",
        "        pred\n",
        "    )\n",
        "    results[i] = result\n",
        "    if result.is_solved:\n",
        "        num_succ += 1\n",
        "\n",
        "print(\"Solved: {} of {} examples\".format(num_succ, len(dataset.dataset)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lhq-S-vcGxUQ"
      },
      "source": [
        "### Save Validation Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DuxS691_fuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(destination_path):\n",
        "    os.makedirs(destination_path)\n",
        "\n",
        "with open(os.path.join(destination_path, \"result.pickle\"), \"wb\") as f:\n",
        "    pickle.dump(results, f)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}